# TextChunker åˆ†å—åŸç†è¯¦è§£

## é—®é¢˜ 1ï¼šä¸ºä»€ä¹ˆè¦å…ˆåˆ†è¡Œï¼Œå†åˆ†æ®µï¼Ÿ

### ä¸¤é˜¶æ®µåˆ†å—ç­–ç•¥

TextChunker ä½¿ç”¨ **ä¸¤é˜¶æ®µåˆ†å—** æ¥ä¿ç•™è¯­ä¹‰å®Œæ•´æ€§ï¼š

```
åŸå§‹æ–‡æœ¬
    â†“
ç¬¬ä¸€é˜¶æ®µï¼šSplitPlainTextLines (åˆ†è¡Œ)
    â†“
    è¡Œåˆ—è¡¨
    â†“
ç¬¬äºŒé˜¶æ®µï¼šSplitPlainTextParagraphs (åˆ†æ®µ)
    â†“
æœ€ç»ˆçš„æ®µè½ï¼ˆå—ï¼‰
```

### ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

#### 1. åˆ†è¡Œé˜¶æ®µ - ç»†ç²’åº¦æ§åˆ¶
**ç›®çš„**ï¼šå°†è¶…é•¿çš„å¥å­æ‹†åˆ†æˆæ›´å°çš„å•å…ƒ

**åˆ†éš”ç¬¦ä¼˜å…ˆçº§**ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
```csharp
["\n", ".ã€‚ï¼", "?!", ";", ":", ",ï¼Œã€", ")]}", " ", "-", null]
```

**ç¤ºä¾‹**ï¼š
```
åŸå§‹æ–‡æœ¬ï¼ˆå‡è®¾ maxTokensPerLine = 20ï¼‰ï¼š
"å¨å°¼æ–¯ä½äºæ„å¤§åˆ©ä¸œåŒ—éƒ¨ï¼Œä»¥å…¶ç‹¬ç‰¹çš„åœ°ç†ç‰¹å¾è€Œé—»åã€‚å®ƒå»ºåœ¨äºšå¾—é‡Œäºšæµ·æ³»æ¹–ä¸­çš„100å¤šä¸ªå°å²›ä¸Šã€‚"

åˆ†è¡Œç»“æœï¼š
[
  "å¨å°¼æ–¯ä½äºæ„å¤§åˆ©ä¸œåŒ—éƒ¨ï¼Œä»¥å…¶ç‹¬ç‰¹çš„åœ°ç†ç‰¹å¾è€Œé—»åã€‚",  // åœ¨å¥å·å¤„åˆ†å‰²
  "å®ƒå»ºåœ¨äºšå¾—é‡Œäºšæµ·æ³»æ¹–ä¸­çš„100å¤šä¸ªå°å²›ä¸Šã€‚"
]
```

#### 2. åˆ†æ®µé˜¶æ®µ - è¯­ä¹‰æ•´åˆ
**ç›®çš„**ï¼šå°†ç›¸å…³çš„è¡Œç»„åˆæˆæ®µè½ï¼Œä½†ä¸è¶…è¿‡æœ€å¤§ Token é™åˆ¶

**ç¤ºä¾‹**ï¼š
```
è¡Œåˆ—è¡¨ï¼ˆ3 è¡Œï¼Œæ¯è¡Œ 10 tokensï¼‰ï¼š
[
  "Semantic Kernel æ˜¯ä¸€ä¸ªå¼€æº SDKã€‚",           // 10 tokens
  "å®ƒè®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾é›†æˆå¤§è¯­è¨€æ¨¡å‹ã€‚",        // 10 tokens
  "æ”¯æŒ OpenAIã€Azure OpenAI ç­‰æœåŠ¡ã€‚"         // 10 tokens
]

åˆ†æ®µç»“æœï¼ˆmaxTokensPerParagraph = 25ï¼‰ï¼š
[
  "Semantic Kernel æ˜¯ä¸€ä¸ªå¼€æº SDKã€‚\nå®ƒè®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾é›†æˆå¤§è¯­è¨€æ¨¡å‹ã€‚",  // 20 tokens
  "æ”¯æŒ OpenAIã€Azure OpenAI ç­‰æœåŠ¡ã€‚"                                      // 10 tokens
]
```

### ä¸ºä»€ä¹ˆä¸èƒ½ä¸€æ­¥åˆ°ä½ï¼Ÿ

**åä¾‹ï¼šç›´æ¥åˆ†æ®µï¼ˆä¸åˆ†è¡Œï¼‰**
```
åŸå§‹è¶…é•¿å¥å­ï¼ˆ100 tokensï¼‰ï¼š
"å¨å°¼æ–¯ä½äºæ„å¤§åˆ©ä¸œåŒ—éƒ¨ä»¥å…¶ç‹¬ç‰¹çš„åœ°ç†ç‰¹å¾è€Œé—»åå®ƒå»ºåœ¨äºšå¾—é‡Œäºšæµ·æ³»æ¹–ä¸­çš„..."

å¦‚æœ maxTokensPerParagraph = 50ï¼š
âŒ å¯èƒ½åœ¨è¯è¯­ä¸­é—´æ–­å¼€ï¼Œç ´åè¯­ä¹‰
âŒ æ— æ³•æŒ‰ç…§æ ‡ç‚¹ç¬¦å·ä¼˜å…ˆçº§åˆ†å‰²
```

**æ­£ç¡®åšæ³•ï¼šå…ˆåˆ†è¡Œï¼Œå†åˆ†æ®µ**
```
1. åˆ†è¡Œï¼šåœ¨å¥å·ã€é€—å·ç­‰å¤„åˆ†å‰² â†’ è¯­ä¹‰å®Œæ•´çš„è¡Œ
2. åˆ†æ®µï¼šå°†å¤šä¸ªè¡Œç»„åˆ â†’ è¯­ä¹‰è¿è´¯çš„æ®µè½
```

---

## é—®é¢˜ 2ï¼štokenCounter æ˜¯ä»€ä¹ˆï¼Ÿ

### æ˜¯çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå§”æ‰˜ï¼ˆDelegateï¼‰ï¼

**æºç å®šä¹‰**ï¼š
```csharp
// åœ¨ TextChunker.cs ç¬¬ 52 è¡Œ
public delegate int TokenCounter(string input);
```

### ä»€ä¹ˆæ˜¯å§”æ‰˜ï¼Ÿ

å§”æ‰˜æ˜¯ C# ä¸­çš„ **å‡½æ•°æŒ‡é’ˆ**ï¼Œå¯ä»¥æŠŠæ–¹æ³•ä½œä¸ºå‚æ•°ä¼ é€’ã€‚

**ç±»æ¯”**ï¼š
- æ™®é€šå‚æ•°ï¼šä¼ é€’ **æ•°æ®**ï¼ˆå¦‚ intã€stringï¼‰
- å§”æ‰˜å‚æ•°ï¼šä¼ é€’ **è¡Œä¸º/å‡½æ•°**

### å…·ä½“ç”¨æ³•

#### æ–¹å¼ 1ï¼šä½¿ç”¨ Lambda è¡¨è¾¾å¼ï¼ˆæœ€å¸¸è§ï¼‰
```csharp
var tokenizer = TiktokenTokenizer.CreateForModel("gpt-4");

var lines = TextChunker.SplitPlainTextLines(
    text,
    maxTokensPerLine: 30,
    tokenCounter: text => tokenizer.CountTokens(text)  // ğŸ‘ˆ è¿™å°±æ˜¯å§”æ‰˜ï¼
    //           ^^^^   ^^^^^^^^^^^^^^^^^^^^^^^
    //           å‚æ•°   æ–¹æ³•ä½“
);
```

#### æ–¹å¼ 2ï¼šä½¿ç”¨æ–¹æ³•ç»„ï¼ˆMethod Groupï¼‰
```csharp
var tokenizer = TiktokenTokenizer.CreateForModel("gpt-4");

var lines = TextChunker.SplitPlainTextLines(
    text,
    maxTokensPerLine: 30,
    tokenCounter: tokenizer.CountTokens  // ğŸ‘ˆ ç›´æ¥ä¼ é€’æ–¹æ³•
);
```

#### æ–¹å¼ 3ï¼šå®šä¹‰ç‹¬ç«‹æ–¹æ³•
```csharp
// å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç­¾ååŒ¹é… TokenCounter
int MyTokenCounter(string input)
{
    var tokenizer = TiktokenTokenizer.CreateForModel("gpt-4");
    return tokenizer.CountTokens(input);
}

// ä½¿ç”¨æ–¹æ³•åä½œä¸ºå§”æ‰˜
var lines = TextChunker.SplitPlainTextLines(
    text,
    maxTokensPerLine: 30,
    tokenCounter: MyTokenCounter  // ğŸ‘ˆ ä¼ é€’æ–¹æ³•å
);
```

#### æ–¹å¼ 4ï¼šä¸ä¼ ï¼ˆä½¿ç”¨é»˜è®¤ï¼‰
```csharp
var lines = TextChunker.SplitPlainTextLines(
    text,
    maxTokensPerLine: 30
    // ä¸ä¼  tokenCounterï¼Œä½¿ç”¨é»˜è®¤ï¼šå­—ç¬¦æ•° / 4
);
```

---

## é—®é¢˜ 3ï¼šToken è®¡æ•°å™¨æ˜¯ä»€ä¹ˆé¬¼ï¼Ÿ

### ä»€ä¹ˆæ˜¯ Tokenï¼Ÿ

**Token ä¸ç­‰äºå­—ç¬¦ï¼** Token æ˜¯ LLM çš„åŸºæœ¬å¤„ç†å•å…ƒã€‚

#### è‹±æ–‡ç¤ºä¾‹
```
æ–‡æœ¬: "Hello World"
å­—ç¬¦æ•°: 11 ä¸ªå­—ç¬¦
Token æ•°: 2 ä¸ª Token ["Hello", " World"]
```

#### ä¸­æ–‡ç¤ºä¾‹
```
æ–‡æœ¬: "ä½ å¥½ä¸–ç•Œ"
å­—ç¬¦æ•°: 4 ä¸ªå­—ç¬¦
Token æ•°: çº¦ 4-8 ä¸ª Tokenï¼ˆå–å†³äº Tokenizerï¼‰
```

### ä¸ºä»€ä¹ˆéœ€è¦ Token è®¡æ•°å™¨ï¼Ÿ

#### 1. ç²¾ç¡®æ§åˆ¶ä¸Šä¸‹æ–‡çª—å£
```
GPT-4 ä¸Šä¸‹æ–‡é™åˆ¶: 8192 tokens
å¦‚æœç”¨å­—ç¬¦æ•°ä¼°ç®—: å¯èƒ½è¶…é™å¯¼è‡´ API æŠ¥é”™
å¦‚æœç”¨ Token æ•°: ç²¾ç¡®æ§åˆ¶ï¼Œä¸ä¼šè¶…é™
```

#### 2. ä¸åŒæ¨¡å‹çš„ Tokenizer ä¸åŒ
```
OpenAI (Tiktoken):     "Semantic Kernel" â†’ 2 tokens
Llama (SentencePiece): "Semantic Kernel" â†’ 3 tokens
```

### é»˜è®¤ Token è®¡æ•°å™¨ vs Tiktoken

#### é»˜è®¤è®¡æ•°å™¨ï¼ˆä¸ä¼  tokenCounterï¼‰
```csharp
// æºç ï¼šTextChunker.cs ç¬¬ 358-362 è¡Œ
private static int GetDefaultTokenCount(int length)
{
    return length >> 2;  // ç­‰ä»·äº length / 4
}
```

**é—®é¢˜**ï¼š
- âŒ ä¸å‡†ç¡®ï¼ˆå°¤å…¶æ˜¯ä¸­æ–‡ï¼‰
- âŒ æ— æ³•åæ˜ çœŸå®çš„ Token æ¶ˆè€—

#### Tiktoken è®¡æ•°å™¨ï¼ˆæ¨èï¼‰
```csharp
var tokenizer = TiktokenTokenizer.CreateForModel("gpt-4");
int tokenCount = tokenizer.CountTokens("Semantic Kernel");  // ç²¾ç¡®è®¡ç®—
```

**ä¼˜åŠ¿**ï¼š
- âœ… ä¸ OpenAI API ä½¿ç”¨ç›¸åŒçš„è®¡æ•°æ–¹å¼
- âœ… å‡†ç¡®æ§åˆ¶æˆæœ¬ï¼ˆAPI æŒ‰ Token è®¡è´¹ï¼‰
- âœ… é¿å…ä¸Šä¸‹æ–‡æº¢å‡º

---

## å®Œæ•´ç¤ºä¾‹å¯¹æ¯”

### ç¤ºä¾‹ 1ï¼šä¸ä½¿ç”¨ Token è®¡æ•°å™¨
```csharp
var text = "Semantic Kernel æ˜¯ä¸€ä¸ªå¼€æº SDKï¼Œç”¨äºé›†æˆå¤§è¯­è¨€æ¨¡å‹ã€‚";

var lines = TextChunker.SplitPlainTextLines(
    text,
    maxTokensPerLine: 10
    // é»˜è®¤è®¡æ•°ï¼š28 å­—ç¬¦ / 4 = 7 tokens
);
```

### ç¤ºä¾‹ 2ï¼šä½¿ç”¨ Tiktokenï¼ˆæ¨èï¼‰
```csharp
var text = "Semantic Kernel æ˜¯ä¸€ä¸ªå¼€æº SDKï¼Œç”¨äºé›†æˆå¤§è¯­è¨€æ¨¡å‹ã€‚";
var tokenizer = TiktokenTokenizer.CreateForModel("gpt-4");

var lines = TextChunker.SplitPlainTextLines(
    text,
    maxTokensPerLine: 10,
    tokenCounter: text => tokenizer.CountTokens(text)
    // ç²¾ç¡®è®¡æ•°ï¼šå®é™… Token æ•°ï¼ˆçº¦ 15-20 tokensï¼‰
);
```

---

## å§”æ‰˜çš„æœ¬è´¨

```csharp
// å§”æ‰˜å®šä¹‰
public delegate int TokenCounter(string input);

// ç­‰ä»·äºè¿™æ ·çš„æ¥å£
public interface ITokenCounter
{
    int Count(string input);
}

// ä½†å§”æ‰˜æ›´ç®€æ´ï¼
```

### å§”æ‰˜ vs ç›´æ¥è°ƒç”¨

#### ä¸ä½¿ç”¨å§”æ‰˜ï¼ˆç¡¬ç¼–ç ï¼‰
```csharp
public static List<string> SplitText(string text)
{
    var tokenizer = TiktokenTokenizer.CreateForModel("gpt-4");
    int count = tokenizer.CountTokens(text);
    // âŒ æ— æ³•åˆ‡æ¢å…¶ä»– Tokenizer
}
```

#### ä½¿ç”¨å§”æ‰˜ï¼ˆçµæ´»ï¼‰
```csharp
public static List<string> SplitText(
    string text,
    Func<string, int> tokenCounter)  // å§”æ‰˜å‚æ•°
{
    int count = tokenCounter(text);  // è°ƒç”¨ä¼ å…¥çš„æ–¹æ³•
    // âœ… å¯ä»¥ä¼ å…¥ä»»ä½•è®¡æ•°é€»è¾‘
}
```

---

## æ€»ç»“

| æ¦‚å¿µ | è§£é‡Š | åŸå›  |
|------|------|------|
| **å…ˆåˆ†è¡Œï¼Œå†åˆ†æ®µ** | ä¸¤é˜¶æ®µç­–ç•¥ | 1. ä¿ç•™è¯­ä¹‰å®Œæ•´æ€§<br>2. æŒ‰æ ‡ç‚¹ç¬¦å·ä¼˜å…ˆçº§åˆ†å‰²<br>3. é¿å…åœ¨è¯è¯­ä¸­é—´æ–­å¼€ |
| **tokenCounter å§”æ‰˜** | å‡½æ•°ä½œä¸ºå‚æ•°ä¼ é€’ | 1. çµæ´»åˆ‡æ¢è®¡æ•°é€»è¾‘<br>2. æ”¯æŒä¸åŒçš„ Tokenizer<br>3. å¯é€‰å‚æ•°ï¼ˆé»˜è®¤ï¼šå­—ç¬¦æ•°/4ï¼‰ |
| **Token è®¡æ•°å™¨** | ç²¾ç¡®è®¡ç®— Token æ•°é‡ | 1. Token â‰  å­—ç¬¦<br>2. ç²¾ç¡®æ§åˆ¶ API æˆæœ¬<br>3. é¿å…ä¸Šä¸‹æ–‡çª—å£æº¢å‡º |

### æœ€ä½³å®è·µ

```csharp
// âœ… æ¨èï¼šä½¿ç”¨ Tiktoken
var tokenizer = TiktokenTokenizer.CreateForModel("gpt-4");
var lines = TextChunker.SplitPlainTextLines(text, 30, t => tokenizer.CountTokens(t));
var chunks = TextChunker.SplitPlainTextParagraphs(lines, 100, 10, t => tokenizer.CountTokens(t));

// âŒ ä¸æ¨èï¼šä½¿ç”¨é»˜è®¤è®¡æ•°å™¨ï¼ˆä¸å‡†ç¡®ï¼‰
var lines = TextChunker.SplitPlainTextLines(text, 30);
var chunks = TextChunker.SplitPlainTextParagraphs(lines, 100);
```
