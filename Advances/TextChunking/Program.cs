using Common;
using Microsoft.Extensions.AI;
using Microsoft.Extensions.VectorData;
using Microsoft.ML.Tokenizers;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Connectors.InMemory;
using Microsoft.SemanticKernel.Text;

namespace TextChunking;

// TextChunker ç”¨äºå°†é•¿æ–‡æœ¬æ‹†åˆ†ä¸ºè¯­ä¹‰å®Œæ•´çš„å—ï¼Œæ˜¯ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çš„å…³é”®æ­¥éª¤
// ä¸¤é˜¶æ®µåˆ†å—ï¼šå…ˆåˆ†è¡Œï¼ˆä¿è¯å¥å­å®Œæ•´æ€§ï¼‰â†’ å†åˆ†æ®µï¼ˆæ§åˆ¶å—å¤§å°)
// å®Œæ•´ RAG æµç¨‹ï¼šåˆ†å— â†’ å‘é‡åŒ– â†’ å­˜å‚¨ â†’ æœç´¢
class Program
{
    static async Task Main(string[] args)
    {

        // ã€1ã€‘Markdownæ–‡æœ¬åˆ†å—,ä½¿ç”¨SplitMarkDownLineså’ŒSplitMarkdownParagraphsä¸“ç”¨åˆ†æ³•
        // åˆ†éš”ç¬¦ä¼˜å…ˆçº§ä¸åŒï¼šæ ‡ç‚¹ç¬¦å·ä¼˜å…ˆäºæ¢è¡Œç¬¦,å°½é‡ä¿ç•™Markdownç»“æ„å®Œæ•´æ€§ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰ï¼‰
        const string markdownText = """
            # Semantic Kernel ä»‹ç»
            ## ä»€ä¹ˆæ˜¯ Semantic Kernelï¼Ÿ
            Semantic Kernel æ˜¯å¾®è½¯æ¨å‡ºçš„è½»é‡çº§ SDKï¼Œè®©ä½ èƒ½å¤Ÿè½»æ¾åœ°å°†**å¤§è¯­è¨€æ¨¡å‹ (LLM)** é›†æˆåˆ°åº”ç”¨ç¨‹åºä¸­ã€‚
            ### æ ¸å¿ƒç‰¹æ€§
            - **æ’ä»¶ç³»ç»Ÿ**: å¯æ‰©å±•çš„æ’ä»¶æ¶æ„
            - **æç¤ºæ¨¡æ¿**: æ”¯æŒ Handlebarsã€Liquid ç­‰æ¨¡æ¿å¼•æ“
            - **å‡½æ•°è°ƒç”¨**: è‡ªåŠ¨å‡½æ•°è°ƒç”¨å’Œç¼–æ’
            - **RAG æ”¯æŒ**: å†…ç½®å‘é‡å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½
            ## å¿«é€Ÿå¼€å§‹
            ```csharp
            var kernel = Kernel.CreateBuilder()
                .AddOpenAIChatCompletion("gpt-4", "api-key")
                .Build();
            ```
            """;

        // ä½¿ç”¨ Markdown ä¸“ç”¨çš„åˆ†å—æ–¹æ³•
        // ä¸çº¯æ–‡æœ¬çš„åŒºåˆ«ï¼šåˆ†éš”ç¬¦ä¼˜å…ˆçº§ä¸åŒï¼Œæ›´é€‚åˆ Markdown çš„è¯­æ³•ç»“æ„
        var markdownLines = TextChunker.SplitMarkDownLines(markdownText, maxTokensPerLine: 30);
        var markdownParagraphs = TextChunker.SplitMarkdownParagraphs(markdownLines, maxTokensPerParagraph: 50);
        Console.WriteLine($"åˆ†å‰²ç»“æœ: {markdownParagraphs.Count} ä¸ªå—\n");
        for (int i = 0; i < markdownParagraphs.Count; i++)
        {
            Console.WriteLine($"å— {i + 1}:");
            Console.WriteLine($"{markdownParagraphs[i]}\n");
            Console.WriteLine(new string('-', 60));
        }
        // ã€2ã€‘å®Œæ•´ RAG æµç¨‹ï¼ˆåˆ†å— â†’ å‘é‡åŒ– â†’ å­˜å‚¨ â†’ æœç´¢ï¼‰
        const string ragText = """
            Semantic Kernel æ˜¯ä¸€ä¸ªå¼€æº SDKï¼Œå®ƒè®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾åœ°å°†å¤§è¯­è¨€æ¨¡å‹é›†æˆåˆ°åº”ç”¨ä¸­ã€‚
            å®ƒæ”¯æŒå¤šç§ AI æœåŠ¡ï¼ŒåŒ…æ‹¬ OpenAIã€Azure OpenAIã€Hugging Face ç­‰ã€‚
            æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ï¼šKernelï¼ˆå†…æ ¸ï¼‰ã€Pluginsï¼ˆæ’ä»¶ï¼‰ã€Memoryï¼ˆå†…å­˜ï¼‰ã€Plannersï¼ˆè§„åˆ’å™¨ï¼‰ã€‚
            é€šè¿‡è¿™äº›ç»„ä»¶ï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºå¼ºå¤§çš„ AI åº”ç”¨ã€‚
            TextChunker æ˜¯ Semantic Kernel ä¸­çš„æ–‡æœ¬åˆ†å—å·¥å…·ï¼Œç”¨äºå°†é•¿æ–‡æœ¬æ‹†åˆ†ä¸ºè¯­ä¹‰å®Œæ•´çš„å—ã€‚
            å®ƒæ”¯æŒçº¯æ–‡æœ¬å’Œ Markdown æ ¼å¼ï¼Œå¯ä»¥è‡ªå®šä¹‰ Token è®¡æ•°å™¨ï¼Œå¹¶æ”¯æŒå—ä¹‹é—´çš„é‡å ã€‚
            å‘é‡å­˜å‚¨æ˜¯ RAG çš„æ ¸å¿ƒç»„ä»¶ï¼ŒSemantic Kernel æ”¯æŒå¤šç§å‘é‡æ•°æ®åº“ã€‚
            åŒ…æ‹¬ Qdrantã€Chromaã€Pineconeã€InMemory ç­‰ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å­˜å‚¨æ–¹æ¡ˆã€‚
            """;
        // æ­¥éª¤ 1ï¼šæ–‡æœ¬åˆ†å—
        Console.WriteLine("ğŸ“ æ­¥éª¤ 1ï¼šæ–‡æœ¬åˆ†å—");
        Console.WriteLine(new string('â”€', 60));
        // ä½¿ç”¨Tiktokenå¯ä»¥ç²¾ç¡®è®¡æ•°ï¼Œé»˜è®¤çš„æ•ˆæœä¸å¤Ÿå‡†ç¡®
        var ragTokenizer = TiktokenTokenizer.CreateForModel("gpt-4");
        // ä¸¤é˜¶æ®µåˆ†å—ï¼šå…ˆåˆ†è¡Œï¼Œå†åˆ†æ®µ
        var ragLines = TextChunker.SplitPlainTextLines(
            ragText,
            maxTokensPerLine: 30,
            tokenCounter: t => ragTokenizer.CountTokens(t));
        // ä½¿ç”¨é‡å æé«˜æ£€ç´¢æ•ˆæœ
        var ragChunks = TextChunker.SplitPlainTextParagraphs(
            ragLines,
            maxTokensPerParagraph: 50,
            overlapTokens: 10,  // å—ä¹‹é—´æœ‰10ä¸ªTokençš„é‡å 
            tokenCounter: t => ragTokenizer.CountTokens(t));
        Console.WriteLine($"âœ… åŸå§‹æ–‡æœ¬åˆ†å‰²ä¸º {ragChunks.Count} ä¸ªå—");
        for (int i = 0; i < ragChunks.Count; i++)
        {
            var tokenCount = ragTokenizer.CountTokens(ragChunks[i]);
            Console.WriteLine($"å— {i + 1}: {tokenCount} tokens");
        }
        Console.WriteLine();

        // åˆ›å»º Embedding Generatorï¼ˆå‘é‡ç”Ÿæˆå™¨ï¼‰
        var embeddingGenerator = Settings.CreateEmbeddingGenerator();
        // åˆ›å»ºInMemoryå†…å­˜å‘é‡å­˜å‚¨,ç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨ï¼šQdrantã€Chromaã€Pinecone ç­‰
        var vectorStore = new InMemoryVectorStore(new() { EmbeddingGenerator = embeddingGenerator });
        // è·å–æˆ–åˆ›å»ºé›†åˆï¼ˆç±»ä¼¼æ•°æ®åº“ä¸­çš„è¡¨ï¼‰
        var collection = vectorStore.GetCollection<int, ChunkDataModel>("text_chunks");
        await collection.EnsureCollectionExistsAsync();
        // éå†æ¯ä¸ªæ–‡æœ¬å—ï¼Œç”Ÿæˆå‘é‡å¹¶å­˜å‚¨
        for (int i = 0; i < ragChunks.Count; i++)
        {
            // åˆ›å»ºæ•°æ®æ¨¡å‹
            // ChunkDataModel ä½¿ç”¨ [VectorStoreVector] ç‰¹æ€§æ ‡æ³¨
            // Content å­—æ®µä¼šè‡ªåŠ¨è½¬æ¢ä¸ºå‘é‡ï¼ˆé€šè¿‡ Embedding => Contentï¼‰
            var record = new ChunkDataModel
            {
                Key = i + 1,
                ChunkIndex = i + 1,
                Content = ragChunks[i],
                TokenCount = ragTokenizer.CountTokens(ragChunks[i])
            };
            // Upsertï¼šæ’å…¥æˆ–æ›´æ–°è®°å½•
            // VectorStore ä¼šè‡ªåŠ¨è°ƒç”¨ EmbeddingGenerator ç”Ÿæˆå‘é‡
            await collection.UpsertAsync(record);
            Console.WriteLine($"   âœ… å— {i + 1} å·²å­˜å‚¨å¹¶å‘é‡åŒ–");
        }
        Console.WriteLine($"\nğŸ’¡ å…±å­˜å‚¨äº† {ragChunks.Count} ä¸ªæ–‡æœ¬å—åˆ°å‘é‡æ•°æ®åº“\n");
        // å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        var queryEmbedding = await embeddingGenerator.GenerateAsync("æ”¯æŒå“ªäº›å‘é‡æ•°æ®åº“ï¼Ÿ");
        // æ‰§è¡Œå‘é‡æœç´¢,SearchAsyncä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—æŸ¥è¯¢å‘é‡ä¸æ‰€æœ‰å­˜å‚¨å‘é‡çš„ç›¸ä¼¼åº¦
        var searchResults = await collection.SearchAsync(
            queryEmbedding.Vector,
            top: 2).ToListAsync();
        Console.WriteLine($"æ‰¾åˆ° {searchResults.Count} ä¸ªæœ€ç›¸å…³çš„æ–‡æœ¬å—:\n");
        // æ˜¾ç¤ºæœç´¢ç»“æœ
        for (int i = 0; i < searchResults.Count; i++)
        {
            var result = searchResults[i];
            Console.WriteLine($"   [{i + 1}] ç›¸ä¼¼åº¦: {result.Score:F4}");
            Console.WriteLine($"       å—ç´¢å¼•: {result.Record.ChunkIndex}");
            Console.WriteLine($"       Token æ•°: {result.Record.TokenCount}");
            // æ˜¾ç¤ºå†…å®¹é¢„è§ˆï¼ˆå‰60ä¸ªå­—ç¬¦ï¼‰
            var preview = result.Record.Content.Length > 60
                ? result.Record.Content.Substring(0, 60) + "..."
                : result.Record.Content;
            Console.WriteLine($"       å†…å®¹é¢„è§ˆ: {preview}");
            Console.WriteLine();
        }
    }

}

// åˆ†å—æ•°æ®æ¨¡å‹ - ç”¨äºå‘é‡å­˜å‚¨
public sealed class ChunkDataModel
{
    [VectorStoreKey]
    public int Key { get; init; }

    [VectorStoreData]
    public int ChunkIndex { get; init; }

    [VectorStoreData]
    public string Content { get; init; } = string.Empty;

    [VectorStoreData]
    public int TokenCount { get; init; }

    [VectorStoreVector(768)]  // å‘é‡å­—æ®µï¼šContent ä¼šè‡ªåŠ¨è½¬æ¢æˆ 768 ç»´å‘é‡ç”¨äºè¯­ä¹‰æœç´¢
    public string Embedding => Content;
}
